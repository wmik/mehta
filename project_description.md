# Senior Software Engineer Take Home Assignment

1. ## Introduction and context

At Shamiri, we are solving a massive scalability problem. We deliver evidence-based mental health interventions to young people using a **Tiered Care Model**. This relies on **Shamiri Fellows** (lay providers, usually 18-22 years old) to deliver group therapy, overseen by **Tier 2 Supervisors** (semi-professionals).

As we scale to serve 10 million youths, our Supervisors are facing a quality assurance bottleneck. They cannot listen to every single session recording to ensure safety and protocol adherence.

**Your Mission:** Build a "Mini-Product" that amplifies a Supervisor's capacity to review sessions using Generative AI.

2. ## The Assignment

You will build the **"Shamiri Supervisor Copilot."**

This is a web-based dashboard where a Supervisor **can log in**, view a list of therapy sessions conducted by Fellows **assigned to them**, and view an AI-generated session analysis of those 1 hour long sessions.

### Core Requirements

The following are the minimum set of requirements that the application **must meet.** However, feel free to extend this as you see fit.

#### A. The Dashboard (Next.js)

* A view listing at least 10 "Completed Sessions."

* Each session should display metadata: Fellow Name, Date, Group ID, and a **Status** (e.g., *Processed, Flagged for Review, Safe*).

* ***Note:*** You should seed your database with mock text transcripts representing these therapy sessions. Your mock text transcripts should contain text ranging from 40-60 minute long therapy sessions. Feel free to use synthetic text generators for this.

#### B. The AI Analysis Engine (The Core Feature)

* When a Supervisor clicks on a session, they should see a **Session Insight Card** generated by an LLM (OpenAI, Anthropic, etc.).

* The AI must analyze the transcript and output structured data containing:

  1. **Session Summary:** A 3-sentence summary.

  2. **Quantitative scores with qualitative justifications:** Did the Fellow teach the assigned concept (e.g., "Growth Mindset")?. The grading rubric is attached in the [**APPENDIX section**](#appendix-a:-the-grading-rubric-\(simplified\))

  3. **Risk Detection (Critical):** A binary flag (**SAFE** or **RISK**). If the text contains indications of self-harm or severe crisis, it must be flagged, and the specific quote extracted.

#### C. The Human-in-the-Loop

* AI is not perfect. The Supervisor must be able to **Validate** or **Reject** the AI's findings.

* *Example:* The AI flags a session as "Risk," but the Supervisor reviews it and sees it was a misunderstanding. The Supervisor changes the status to "Safe" and adds a note.

3. ## Technical Stack & Constraints

* **Framework:** Next.js

* **Language:** TypeScript is highly preferred.

* **Database:** Any SQL flavor (Postgres strongly preferred).

* **Hosting:** The final application must be deployed publicly (Vercel, Netlify, or Railway)

4. ## AI Policy

We believe the future of software engineering involves human-AI collaboration.

* **AI Usage:** You are **encouraged** to use AI coding tools (Cursor, Claude code etc.).

* **The Catch:** You must explain *how* you used them. We want to hire engineers who know how to orchestrate AI, not just follow it blindly.

* **Documentation:** In your submission, include a brief section on which parts were AI-generated versus hand-coded, and how you verified the code quality.

5. ## Evaluation Rubric

| Criteria | What we will be looking for |
| :---- | :---- |
| **Engineering Architecture** | Logical data modeling (Fellows vs. Sessions). Type safety. Handling AI latency (streaming, loading states, or optimistic UI). |
| **AI Engineering** | Do not just send raw text to an LLM. We would like to see structured output enforcement (Zod/JSON schema), defensive prompting, and error handling. |
| **Product Sense & UX** | Is the UI intuitive for a non-tech literate Supervisor? Is the "Risk" flag obvious and urgent? Does the design feel professional? |
| **Shamiri Alignment** | Research our work. Did you use the correct terminology (Fellows, Tiered Care)? Does the app feel lightweight and accessible for an African context? |

6. ##  A Note on Time

We have allotted **10 days** for this. This does not mean we expect 10 days of full-time coding. We want to give you enough buffer to think deeply, design an architecture you are proud of, and fit this around your current schedule.

**Good luck.** We are looking for engineers who build with empathy, precision, and scale. Show us what you can do.

7. ## Submission

Please use this google form to submit your task: [https://forms.gle/UU8LGnki53LNCVf88](https://forms.gle/UU8LGnki53LNCVf88)

## 

## Appendix A: The Grading Rubric (Simplified) {#appendix-a:-the-grading-rubric-(simplified)}

### Note to Candidate:

In our actual production environment, we use 6 metrics with 7 point likert scales. For this assignment, we have adapted our protocol into a simplified **3-Point Quality Index** to make it easier for you to engineer the LLM prompt.

Your AI solution should evaluate every session transcript against these three metrics.

#### Metric 1: Content Coverage (Did they teach the material?)

* **Context:** The Fellow is supposed to teach the concept of "Growth Mindset" (the belief that abilities can be developed through dedication and hard work).

* **What the AI should look for:** Key phrases like "brain is a muscle," "learning from failure," or "effort matters more than talent."

| Score | Rating | Criteria |
| :---- | :---- | :---- |
| **1** | **Missed** | The Fellow failed to mention "Growth Mindset" or defined it incorrectly (e.g., claiming intelligence is fixed). |
| **2** | **Partial** | The Fellow mentioned the concept but moved on quickly without checking if students understood. |
| **3** | **Complete** | The Fellow explained the concept clearly, gave an example, and asked the group for their thoughts. |

#### 

#### Metric 2: Facilitation Quality (How did they deliver it?)

* **Context:** We need Fellows who are empathetic, clear, and engaging. They should not just read from a script like a robot.

* **What the AI should look for:** Open-ended questions ("What do you think?"), validating statements ("Thank you for sharing that"), and clear language.

| Score | Rating | Criteria |
| :---- | :---- | :---- |
| **1** | **Poor** | The Fellow dominated the conversation (monologue), interrupted students, or used confusing jargon. |
| **2** | **Adequate** | The Fellow was polite but transactional. They stuck to the script but didn't engage deeply. |
| **3** | **Excellent** | The Fellow was warm, encouraged quiet members to speak, and validated feelings (e.g., "It sounds like that was really hard for you"). |

#### Metric 3: Protocol Safety (Did they stay within boundaries?)

* **Context:** Shamiri Fellows are lay-providers, not psychiatrists. They must not give medical advice or stray into "pop psychology" outside the protocol.

* **What the AI should look for:** Any advice-giving that isn't about Growth Mindset (e.g., telling a student to stop taking medication or diagnosing them).

| Score | Rating | Criteria |
| :---- | :---- | :---- |
| **1** | **Violation** | The Fellow gave unauthorized advice (medical/relationship) or strayed significantly off-topic. |
| **2** | **Minor Drift** | The Fellow got distracted by a side conversation but eventually brought it back to the topic. |
| **3** | **Adherent** | The Fellow stayed focused on the Shamiri curriculum and handled distractions graceful |

 